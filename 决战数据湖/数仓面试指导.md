# 数仓面试指导

## 定位：
> 中高级数仓工程师
## 个人问题
> 沟通表达、项目描述、技术、积极投简历
> 涉足要点数据治理
## 设计到的技能
> 数仓的搭建，数仓模型的设计，通过sql完成一些业务，生成相关报表
## 项目简述
> 涉及的架构有：星型模型，雪花模型
> 企业级数据中台------->数仓------> 纬度建模（常用）
> 项目背景：某央企（电视传媒行业）数据中台
> 智慧政务   ----> 三范式建模----> 英模工厂
## 技术
### 数仓基础
#### 数仓基本认识
#### 数仓架构
##### kimball架构---维度建模
###### 雪花模型
####### 确认事表
####### 确认维度
####### 确认粒度
###### 星型模型
##### inmon工厂架构---三范式建模
##### 分层
#### 搭建数仓流程
##### 确认需求
###### 业务需求
###### 技术需求
##### 确认模型
##### 装载数据
###### 数据接入
###### 建表
###### 装载数据
##### 访问性---应用访问性
##### 维护
### 项目业务
#### 我们是做什么？
#### 事实日志
##### 搜索
##### 播放
##### 充值
##### 登录
#### 维度
##### 一级分类
##### 电视栏目
##### 某个专题主题
##### 节目集
##### 节目
##### 渠道
#### 度量
##### 收视用户数
##### 收视次数
##### 收视时间
### 项目架构
#### 数据接入
#### 数据处理
##### 离线处理
##### 实时处理
#### 数据存储
##### 离线存储
###### hdfs
###### hbase
###### kudv
###### Mongodb
###### es
##### 实时存储
###### redis
###### es
#### 项目展示
##### 报表展示
##### 可视化下展示
## 上班干什么（天津移动）
### 数据接入 配置flume10%
#### thriftsouce
#### filechanal
#### hdfssink 故障转移到另一个目录
### 数据处理spark core 10%

### 数仓装载 60%
#### ods层
##### 1、建立临时表去做数据处理（加载数据），数据处理，orc 和 parquet 区别去背
##### 2、将你的临时表加载到你所在建设表
#### dwd层
##### planid不为空case when / if rownumber over(), concat_ws 时间类函数sqlit unlon all
##### 有开始无结束 有结束无开始
##### 校验时长
###### 时长长度
###### 时长小于0
##### 上一条收视结束时间大于下一条开始时间
#### dw层---轻度聚合 收视人数，收视次数，收视时长 group by 聚合函数计算一些函数
#### dm层---针对某一维度进行抽取聚合left join
#### st层---关联维度表获取维度进行报表层存储
### 其他工作 10%
#### 提供报表sqoop配置
#### shell脚本
#### linux命令
##### wc -l
##### awk sed
##### 内存df -h 存储du -ef 前几行head 后几行tail端口
### 基础数据提供 10%
#### 算法
#### 即席报表
### 实时数仓--sparkstreamming 代码
#### 如何保证数据不堆积
##### spark streamming kafka maxRatePerPartition拿多少条数据
##### 设置批次时间
#### 维护偏移量
